{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "reservoirNet_grid.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m-kazuki/reservoirNet/blob/fujino/reservoirNet_grid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9XpqxcfSDMG",
        "colab_type": "code",
        "outputId": "5351b677-e042-4291-a748-db4de66c8ee8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5Fr1HrmSDxa",
        "colab_type": "code",
        "outputId": "69b0e884-c545-4e0c-e98b-34494eb70e4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd drive/My\\ Drive/reservoirNet"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/reservoirNet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVqji5uesMXQ",
        "colab_type": "code",
        "outputId": "628b2d36-ee1c-401e-e62f-511172cb4ba1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 923
        }
      },
      "source": [
        "!pip install bindsnet"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bindsnet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/47/6eb9adae6a0d24a3f8ef5059192bfe035f0a3b1fd58ce9e30e9e8f74df9f/bindsnet-0.2.7.tar.gz (70kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 4.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.2 in /usr/local/lib/python3.6/dist-packages (from bindsnet) (1.18.2)\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from bindsnet) (1.4.0)\n",
            "Requirement already satisfied: torchvision>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from bindsnet) (0.5.0)\n",
            "Collecting tensorboardX>=1.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f1/5843425495765c8c2dd0784a851a93ef204d314fc87bcc2bbb9f662a3ad1/tensorboardX-2.0-py2.py3-none-any.whl (195kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 14.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.19.9 in /usr/local/lib/python3.6/dist-packages (from bindsnet) (4.38.0)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from bindsnet) (3.2.1)\n",
            "Requirement already satisfied: gym>=0.10.4 in /usr/local/lib/python3.6/dist-packages (from bindsnet) (0.17.1)\n",
            "Requirement already satisfied: scikit_image>=0.13.1 in /usr/local/lib/python3.6/dist-packages (from bindsnet) (0.16.2)\n",
            "Requirement already satisfied: scikit_learn>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from bindsnet) (0.22.2.post1)\n",
            "Requirement already satisfied: opencv-python>=3.4.0.12 in /usr/local/lib/python3.6/dist-packages (from bindsnet) (4.1.2.30)\n",
            "Requirement already satisfied: pytest>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from bindsnet) (3.6.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from bindsnet) (1.4.1)\n",
            "Requirement already satisfied: cython>=0.28.5 in /usr/local/lib/python3.6/dist-packages (from bindsnet) (0.29.16)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.6/dist-packages (from bindsnet) (1.0.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.4.0->bindsnet) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.4.0->bindsnet) (7.0.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX>=1.7->bindsnet) (3.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->bindsnet) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->bindsnet) (2.4.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->bindsnet) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->bindsnet) (0.10.0)\n",
            "Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym>=0.10.4->bindsnet) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym>=0.10.4->bindsnet) (1.5.0)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit_image>=0.13.1->bindsnet) (1.1.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit_image>=0.13.1->bindsnet) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit_image>=0.13.1->bindsnet) (2.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit_learn>=0.19.1->bindsnet) (0.14.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.4.0->bindsnet) (1.8.1)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.4.0->bindsnet) (0.7.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.4.0->bindsnet) (8.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest>=3.4.0->bindsnet) (46.1.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.4.0->bindsnet) (19.3.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.4.0->bindsnet) (1.3.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.4->bindsnet) (2018.9)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.10.4->bindsnet) (0.16.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit_image>=0.13.1->bindsnet) (4.4.2)\n",
            "Building wheels for collected packages: bindsnet\n",
            "  Building wheel for bindsnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bindsnet: filename=bindsnet-0.2.7-cp36-none-any.whl size=81417 sha256=a4f43d0e6af5fc3e31f2b0030e8a40e7023b13daf0708c825a1960af9487264e\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/68/80/eca244a3d072961b5152d5906475ffc9d9b2453c9e060535e3\n",
            "Successfully built bindsnet\n",
            "Installing collected packages: tensorboardX, bindsnet\n",
            "Successfully installed bindsnet-0.2.7 tensorboardX-2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1RJPs4dNBsY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import argparse\n",
        "import matplotlib.pyplot as plt\n",
        "import time as time_package\n",
        "\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from bindsnet.analysis.plotting import (\n",
        "    plot_input,\n",
        "    plot_spikes,\n",
        "    plot_voltages,\n",
        "    plot_weights,\n",
        ")\n",
        "from bindsnet.datasets import MNIST\n",
        "from bindsnet.encoding import PoissonEncoder\n",
        "from bindsnet.network import Network\n",
        "from bindsnet.network.nodes import Input\n",
        "\n",
        "# Build a simple two-layer, input-output network.\n",
        "from bindsnet.network.monitors import Monitor\n",
        "from bindsnet.network.nodes import LIFNodes\n",
        "from bindsnet.network.topology import Connection\n",
        "from bindsnet.utils import get_square_weights\n",
        "\n",
        "import easydict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eJjUiup_Bxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "args = easydict.EasyDict({\n",
        "        \"seed\": 0,\n",
        "        \"n_neurons\": 500,\n",
        "        \"n_epochs\": 500,\n",
        "        \"n_examples\": 1264,\n",
        "        \"n_workers\": -1,\n",
        "        \"time\": 251,\n",
        "        \"dt\": 1.0,\n",
        "        \"intensity\": 64,\n",
        "        \"progress_interval\": 10,\n",
        "        \"update_interval\": 250,\n",
        "        \"gpu\": True,\n",
        "        \"device_id\": 0,\n",
        "        \"train\": True\n",
        "})\n",
        "seed = args.seed\n",
        "n_neurons = args.n_neurons\n",
        "n_epochs = args.n_epochs\n",
        "n_examples = args.n_examples\n",
        "n_workers = args.n_workers\n",
        "time = args.time\n",
        "dt = args.dt\n",
        "intensity = args.intensity\n",
        "progress_interval = args.progress_interval\n",
        "update_interval = args.update_interval\n",
        "train = args.train\n",
        "gpu = args.gpu\n",
        "device_id = args.device_id\n",
        "n_iters = n_examples\n",
        "\n",
        "np.random.seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "# Sets up Gpu use\n",
        "if gpu and torch.cuda.is_available():\n",
        "    torch.cuda.set_device(device_id)\n",
        "    # torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "else:\n",
        "    torch.manual_seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "RtYydfQ6sMXZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dt: the simulation time step\n",
        "network = Network(dt=dt)\n",
        "\n",
        "# 入力層\n",
        "inpt = Input(1600, shape=(1, 1600))\n",
        "network.add_layer(inpt, name=\"I\")\n",
        "\n",
        "# リザーバー層\n",
        "output = LIFNodes(n_neurons, thresh=-52 + np.random.randn(n_neurons).astype(float))\n",
        "network.add_layer(output, name=\"O\")\n",
        "\n",
        "# 入力層->リザーバー層とリザーバー層->リザーバー層のコネクションを作成\n",
        "C1 = Connection(source=inpt, target=output, w=torch.randn(inpt.n, output.n))\n",
        "C2 = Connection(source=output, target=output, w=torch.randn(output.n, output.n))\n",
        "network.add_connection(C1, source=\"I\", target=\"O\")\n",
        "network.add_connection(C2, source=\"O\", target=\"O\")\n",
        "\n",
        "# スパイクのモニター(入力、リザーバー)\n",
        "spikes = {}\n",
        "for l in network.layers:\n",
        "    spikes[l] = Monitor(network.layers[l], [\"s\"], time=time)\n",
        "    network.add_monitor(spikes[l], name=\"%s_spikes\" % l)\n",
        "\n",
        "# ボルトのモニター(リザーバー)\n",
        "voltages = {\"O\": Monitor(network.layers[\"O\"], [\"v\"], time=time)}\n",
        "network.add_monitor(voltages[\"O\"], name=\"O_voltages\")\n",
        "\n",
        "# Directs network to GPU\n",
        "if gpu:\n",
        "    network.to(\"cuda\")\n",
        "\n",
        "# dataset作成\n",
        "class MyDataset(torch.utils.data.Dataset):\n",
        "    # xy.shape = (n, time, xy)\n",
        "    # F.shape = (n, time, F)\n",
        "    def __init__(self, xy, F, transform=None):\n",
        "        self.transform = transform\n",
        "        self.data_num = xy.shape[0]\n",
        "        self.data = xy\n",
        "        self.label = F\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data_num\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        out_data = self.data[idx]\n",
        "        out_label =  self.label[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            out_data = self.transform(out_data)\n",
        "\n",
        "        return out_data, out_label\n",
        "\n",
        "train_data = pd.read_csv(\"grid_data.csv\", header = None)\n",
        "train_data = np.array(train_data)\n",
        "train_data = train_data.reshape((1600,251,4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpzoclB4QemX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grid_data = np.zeros([1264,251,1602])\n",
        "k = 0\n",
        "for datum in train_data:\n",
        "  if datum[0,0]!=0:\n",
        "    #from IPython.core.debugger import Pdb; Pdb().set_trace()\n",
        "    grid_data[k,:,1600:] = datum[:,3:]\n",
        "    target = np.zeros([251,1600])\n",
        "    grid_number = np.int(np.floor((datum[0,:2] + 1)*20)[0] + np.floor((datum[0,:2] + 1)*20)[1]*40)\n",
        "    target[:, grid_number] = 1\n",
        "    grid_data[k,:,:1600] = target\n",
        "    k += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6csZO2FSRBkU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = grid_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJobLVlnNNEc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from IPython.core.debugger import Pdb; Pdb().set_trace()\n",
        "xy = train_data[:,:,:1600]\n",
        "F = train_data[:,:,1600:]\n",
        "dataset = MyDataset(xy, F, transform=None)\n",
        "\n",
        "# Create a dataloader to iterate and batch data\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    dataset, batch_size=1, shuffle=True, num_workers=0, pin_memory=gpu\n",
        ")\n",
        "\n",
        "# Run training data on reservoir computer and store (spikes per neuron, label) per example.\n",
        "train_pairs = []\n",
        "pbar = tqdm(enumerate(dataloader))\n",
        "\n",
        "# このループではトレーニングデータを作成していると考えて良い\n",
        "# q = int((bs-1)/2)\n",
        "for (i, dataPoint) in pbar:\n",
        "    # data, labelを取り出している\n",
        "    datum = dataPoint[0].view(time, 1600).to(device_id)\n",
        "    label = dataPoint[1].view(time, 2)\n",
        "    pbar.set_description_str(\"Train progress: (%d / %d)\" % (i, n_iters))\n",
        "    # 時間を1つ進める\n",
        "    for j in range(50):\n",
        "      network.run(inputs={\"I\": datum[0]}, time=1, input_time_dim=1)\n",
        "    for j in range(251):\n",
        "      # リザーバー層の状態とラベルをトレーニングデータとして保存\n",
        "      train_pairs.append([spikes[\"O\"].get(\"s\").sum(0), label[j]])\n",
        "      for k in range(10):\n",
        "        network.run(inputs={\"I\": datum[0]}, time=1, input_time_dim=1)\n",
        "    network.reset_state_variables()\n",
        "np.save(\"grid_pairs\", train_pairs)\n",
        "# Define logistic regression model using PyTorch."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5D2KbyAqoCYL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NN(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(NN, self).__init__()\n",
        "        self.linear_1 = nn.Linear(input_size, 500)\n",
        "        self.linear_2 = nn.Linear(500, 2)\n",
        "        # self.dropout1 = nn.Dropout(p=0.05)\n",
        "        # self.dropout2 = nn.Dropout(p=0.5)\n",
        "        self.linear = nn.Linear(input_size, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # out = self.dropout1(x.float().view(-1))\n",
        "        # out = torch.relu(self.linear_1(out))\n",
        "        out = torch.relu(self.linear_1(x.float().view(-1)))\n",
        "        # out = torch.sigmoid(self.linear_1(x.float().view(-1)))\n",
        "        # out = self.dropout2(out)\n",
        "        out = self.linear_2(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xu8tpSZ4fblP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_pairs = np.load(\"grid_pairs.npy\", allow_pickle=True)\n",
        "# training_pairs = training_pairs[:2510,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5S-3s9ZoHIN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create and train logistic regression model on reservoir outputs.\n",
        "model = NN(n_neurons).to(device_id)\n",
        "criterion = torch.nn.MSELoss(reduction=\"sum\")\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, betas=(0.5, 0.999))\n",
        "\n",
        "# Training the Model\n",
        "# 回帰モデルを先ほど生成したデータでトレーニング\n",
        "print(\"\\n Training the read out\")\n",
        "# model.train()\n",
        "# model.load_state_dict(torch.load(\"model\"))\n",
        "patience = 30\n",
        "early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "avg_train_losses = []\n",
        "avg_valid_losses = [] \n",
        "start = time_package.time()\n",
        "\n",
        "pbar = tqdm(enumerate(range(n_epochs)))\n",
        "for epoch, _ in pbar:\n",
        "    # model.train()\n",
        "    for i, (s, l) in enumerate(training_pairs):\n",
        "        # Forward + Backward + Optimize\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(s.view(-1))\n",
        "        label = l.float().to(device_id)\n",
        "        loss = criterion(outputs, label)\n",
        "        # avg_loss += loss.data\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "    train_loss = np.average(train_losses)\n",
        "    avg_train_losses.append(train_loss)\n",
        "\n",
        "    pbar.set_description_str(\n",
        "        \"Epoch: %d/%d, train_loss: %.4f\"\n",
        "        % (epoch + 1, n_epochs, train_loss)\n",
        "    )\n",
        "    train_losses = []\n",
        "    \n",
        "    elapsed_time = time_package.time() - start\n",
        "    if elapsed_time > 40000:\n",
        "        print(\"Timeout\")\n",
        "        break\n",
        "\n",
        "torch.save(model.state_dict(), \"model_grid\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSryFpilpDv_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# パラメータの読み込み\n",
        "param = torch.load('model_grid')\n",
        "model = NN(n_neurons).to(device_id)\n",
        "criterion = torch.nn.MSELoss(reduction=\"sum\")\n",
        "model.load_state_dict(param)\n",
        "#model.eval()\n",
        "loss, total = 0, 0\n",
        "k = 0\n",
        "grid_pairs = np.load(\"grid_pairs.npy\", allow_pickle=True)\n",
        "outs = np.zeros([251*1264,2])\n",
        "labels = np.zeros([251*1264,2])\n",
        "for s, label in grid_pairs:\n",
        "    k += 1\n",
        "    outputs = model(s)\n",
        "    outs[k-1,:] = np.array(outputs.cpu().detach().numpy())\n",
        "    labels[k-1,:] = np.array(label.cpu().detach().numpy())\n",
        "    loss += criterion(outputs, label.float().to(device_id)).data\n",
        "    total += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUrabBO08Bb8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l = 0\n",
        "a = 251*l\n",
        "b = a + 251\n",
        "plt.figure(dpi=150)\n",
        "plt.plot(outs[a:b,0])\n",
        "plt.plot(labels[a:b,0])\n",
        "plt.show()\n",
        "plt.figure(dpi=150)\n",
        "plt.plot(outs[a:b,1])\n",
        "plt.plot(labels[a:b,1])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KClbSthhILsI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = np.zeros((251, 2))\n",
        "ans = np.zeros((251, 2))\n",
        "prediction[:,0] = outs[a:b,0]\n",
        "prediction[:,1] = outs[a:b,1]\n",
        "ans[:,0] = labels[a:b,0]\n",
        "ans[:,1] = labels[a:b,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hllb0D9emNcw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.savetxt(\"prediction.csv\",prediction)\n",
        "np.savetxt(\"ans.csv\",ans)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}